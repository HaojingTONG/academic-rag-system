#!/usr/bin/env python3
"""
æµ‹è¯•ç”Ÿæˆè´¨é‡æå‡æ¨¡å—
éªŒè¯ quality_enhancement.py ä¸­å„ä¸ªç»„ä»¶çš„åŠŸèƒ½
"""

import sys
import json
import time
from pathlib import Path

# æ·»åŠ srcåˆ°è·¯å¾„
sys.path.append('src')

def test_imports():
    """æµ‹è¯•æ¨¡å—å¯¼å…¥"""
    print("=" * 60)
    print("1. æµ‹è¯•æ¨¡å—å¯¼å…¥")
    print("=" * 60)
    
    try:
        from src.generator.quality_enhancement import (
            QualityEnhancedGenerator,
            ContextOptimizer,
            PromptEngineer,
            FactChecker,
            CitationManager,
            ContextWindow,
            Citation,
            FactCheckResult
        )
        print("âœ… æ‰€æœ‰ç»„ä»¶å¯¼å…¥æˆåŠŸ")
        return True
    except ImportError as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return False

def test_context_optimizer():
    """æµ‹è¯•ä¸Šä¸‹æ–‡ä¼˜åŒ–å™¨"""
    print("\n" + "=" * 60)
    print("2. æµ‹è¯•ä¸Šä¸‹æ–‡ä¼˜åŒ–å™¨")
    print("=" * 60)
    
    try:
        from src.generator.quality_enhancement import ContextOptimizer
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        mock_results = [
            {
                'content': 'Transformer architecture uses self-attention mechanism to process sequences efficiently.',
                'metadata': {
                    'paper_id': '1706.03762',
                    'title': 'Attention Is All You Need',
                    'section_type': 'abstract',
                    'has_formulas': True,
                    'has_citations': True
                },
                'combined_score': 0.9
            },
            {
                'content': 'BERT demonstrates bidirectional training for language understanding tasks.',
                'metadata': {
                    'paper_id': '1810.04805',
                    'title': 'BERT: Pre-training of Deep Bidirectional Transformers',
                    'section_type': 'results',
                    'has_citations': True
                },
                'combined_score': 0.8
            },
            {
                'content': 'Low relevance content that should be filtered out.',
                'metadata': {
                    'paper_id': 'low_relevance',
                    'title': 'Irrelevant Paper',
                    'section_type': 'content'
                },
                'combined_score': 0.2
            }
        ]
        
        # åˆå§‹åŒ–ä¼˜åŒ–å™¨
        optimizer = ContextOptimizer(max_tokens=1000, min_relevance=0.3)
        
        # æµ‹è¯•ä¸Šä¸‹æ–‡ä¼˜åŒ–
        query = "transformer attention mechanism"
        context_window = optimizer.optimize_context(mock_results, query)
        
        print(f"âœ… ä¸Šä¸‹æ–‡ä¼˜åŒ–æˆåŠŸ")
        print(f"   æºæ–‡æ¡£æ•°: {len(context_window.source_papers)}")
        print(f"   ç›¸å…³æ€§åˆ†æ•°: {context_window.relevance_score:.3f}")
        print(f"   ç½®ä¿¡åº¦: {context_window.confidence_level:.3f}")
        print(f"   Tokenæ•°é‡: {context_window.total_tokens}")
        
        # éªŒè¯è¿‡æ»¤æ•ˆæœ
        assert len(context_window.source_papers) <= len(mock_results), "æºæ–‡æ¡£æ•°é‡åº”è¯¥è¢«è¿‡æ»¤"
        assert context_window.relevance_score > 0, "ç›¸å…³æ€§åˆ†æ•°åº”è¯¥å¤§äº0"
        assert context_window.confidence_level >= 0, "ç½®ä¿¡åº¦åº”è¯¥éè´Ÿ"
        
        return True
        
    except Exception as e:
        print(f"âŒ ä¸Šä¸‹æ–‡ä¼˜åŒ–å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_prompt_engineer():
    """æµ‹è¯•æç¤ºè¯å·¥ç¨‹å¸ˆ"""
    print("\n" + "=" * 60)
    print("3. æµ‹è¯•æç¤ºè¯å·¥ç¨‹å¸ˆ")
    print("=" * 60)
    
    try:
        from src.generator.quality_enhancement import PromptEngineer, ContextWindow
        
        # åˆ›å»ºæç¤ºè¯å·¥ç¨‹å¸ˆ
        engineer = PromptEngineer()
        
        # åˆ›å»ºæ¨¡æ‹Ÿä¸Šä¸‹æ–‡
        context = ContextWindow(
            content="Test context about transformer architecture and attention mechanisms.",
            source_papers=['1706.03762', '1810.04805'],
            relevance_score=0.8,
            confidence_level=0.7,
            total_tokens=500
        )
        
        # æµ‹è¯•ä¸åŒç±»å‹çš„æç¤ºè¯
        test_cases = [
            ("What is transformer architecture?", "definition"),
            ("Compare BERT and GPT models", "comparison"),
            ("How does attention mechanism work?", "methodology"),
            ("What are recent advances in NLP?", "recent_work"),
            ("General AI question", "general")
        ]
        
        for query, intent in test_cases:
            prompt = engineer.generate_prompt(query, intent, context)
            print(f"âœ… {intent} æç¤ºè¯ç”ŸæˆæˆåŠŸ (é•¿åº¦: {len(prompt)} å­—ç¬¦)")
            
            # éªŒè¯æç¤ºè¯åŒ…å«å¿…è¦ä¿¡æ¯
            assert query in prompt, f"æç¤ºè¯åº”è¯¥åŒ…å«æŸ¥è¯¢: {query}"
            assert str(context.confidence_level) in prompt, "æç¤ºè¯åº”è¯¥åŒ…å«ç½®ä¿¡åº¦"
            assert str(len(context.source_papers)) in prompt, "æç¤ºè¯åº”è¯¥åŒ…å«æºæ•°é‡"
        
        # æµ‹è¯•é¢†åŸŸæ£€æµ‹
        domains = engineer._detect_domains("neural networks deep learning attention mechanism")
        print(f"âœ… é¢†åŸŸæ£€æµ‹æˆåŠŸ: {domains}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æç¤ºè¯å·¥ç¨‹å¸ˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_fact_checker():
    """æµ‹è¯•äº‹å®æ ¸æŸ¥å™¨"""
    print("\n" + "=" * 60)
    print("4. æµ‹è¯•äº‹å®æ ¸æŸ¥å™¨")
    print("=" * 60)
    
    try:
        from src.generator.quality_enhancement import FactChecker
        
        # åˆ›å»ºäº‹å®æ ¸æŸ¥å™¨
        checker = FactChecker()
        
        # æµ‹è¯•æ–‡æœ¬
        test_answer = """
        Transformer architecture is a neural network design that uses self-attention mechanisms.
        BERT demonstrates that bidirectional training improves language understanding significantly.
        The method achieves state-of-the-art results on multiple benchmarks.
        This approach outperforms previous RNN-based models in efficiency and accuracy.
        """
        
        # æ¨¡æ‹Ÿæºæ–‡æ¡£
        source_documents = [
            {
                'content': 'Transformer uses self-attention mechanism for parallel processing. This shows significant improvements in efficiency.',
                'metadata': {'paper_id': '1706.03762', 'title': 'Attention Is All You Need'}
            },
            {
                'content': 'BERT demonstrates bidirectional training benefits. The results prove better language understanding.',
                'metadata': {'paper_id': '1810.04805', 'title': 'BERT Paper'}
            }
        ]
        
        # æ‰§è¡Œäº‹å®æ ¸æŸ¥
        fact_results = checker.verify_claims(test_answer, source_documents)
        
        print(f"âœ… äº‹å®æ ¸æŸ¥å®Œæˆ")
        print(f"   æ£€æµ‹åˆ°å£°æ˜æ•°: {len(fact_results)}")
        
        for i, result in enumerate(fact_results[:3], 1):  # åªæ˜¾ç¤ºå‰3ä¸ª
            print(f"   å£°æ˜ {i}: {result.claim[:50]}...")
            print(f"   æ”¯æŒåº¦: {result.support_level}")
            print(f"   ç½®ä¿¡åº¦: {result.confidence_score:.3f}")
            print(f"   æ”¯æŒæº: {len(result.supporting_sources)}")
            print(f"   åå¯¹æº: {len(result.contradicting_sources)}")
        
        # éªŒè¯ç»“æœç»“æ„
        for result in fact_results:
            assert hasattr(result, 'claim'), "ç»“æœåº”è¯¥åŒ…å«å£°æ˜"
            assert hasattr(result, 'support_level'), "ç»“æœåº”è¯¥åŒ…å«æ”¯æŒåº¦"
            assert hasattr(result, 'confidence_score'), "ç»“æœåº”è¯¥åŒ…å«ç½®ä¿¡åº¦"
            assert 0 <= result.confidence_score <= 1, "ç½®ä¿¡åº¦åº”è¯¥åœ¨0-1ä¹‹é—´"
        
        return True
        
    except Exception as e:
        print(f"âŒ äº‹å®æ ¸æŸ¥å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_citation_manager():
    """æµ‹è¯•å¼•ç”¨ç®¡ç†å™¨"""
    print("\n" + "=" * 60)
    print("5. æµ‹è¯•å¼•ç”¨ç®¡ç†å™¨")
    print("=" * 60)
    
    try:
        from src.generator.quality_enhancement import CitationManager
        
        # æµ‹è¯•ä¸åŒå¼•ç”¨æ ¼å¼
        for style in ['APA', 'IEEE']:
            print(f"\næµ‹è¯• {style} æ ¼å¼:")
            manager = CitationManager(citation_style=style)
            
            # æ¨¡æ‹Ÿæºæ•°æ®
            mock_sources = [
                {
                    'content': 'Transformer content...',
                    'metadata': {
                        'paper_id': '1706.03762',
                        'title': 'Attention Is All You Need',
                        'authors': ['Ashish Vaswani', 'Noam Shazeer', 'Niki Parmar'],
                        'published': '2017-06-12'
                    },
                    'relevance_score': 0.9
                },
                {
                    'content': 'BERT content...',
                    'metadata': {
                        'paper_id': '1810.04805',
                        'title': 'BERT: Pre-training of Deep Bidirectional Transformers',
                        'authors': ['Jacob Devlin', 'Ming-Wei Chang', 'Kenton Lee'],
                        'published': '2018-10-11'
                    },
                    'relevance_score': 0.8
                }
            ]
            
            # ç”Ÿæˆå¼•ç”¨
            citations = manager.generate_citations(mock_sources)
            print(f"   ç”Ÿæˆå¼•ç”¨æ•°: {len(citations)}")
            
            # æ ¼å¼åŒ–å¼•ç”¨
            for i, citation in enumerate(citations, 1):
                formatted = manager.format_citation(citation)
                print(f"   [{i}] {formatted}")
                
                # éªŒè¯å¼•ç”¨ç»“æ„
                assert citation.paper_id, "å¼•ç”¨åº”è¯¥æœ‰paper_id"
                assert citation.title, "å¼•ç”¨åº”è¯¥æœ‰æ ‡é¢˜"
                assert citation.year, "å¼•ç”¨åº”è¯¥æœ‰å¹´ä»½"
                assert isinstance(citation.authors, list), "ä½œè€…åº”è¯¥æ˜¯åˆ—è¡¨"
            
            # ç”Ÿæˆå‚è€ƒæ–‡çŒ®
            bibliography = manager.generate_bibliography(citations)
            print(f"   å‚è€ƒæ–‡çŒ®é•¿åº¦: {len(bibliography)} å­—ç¬¦")
            assert "References:" in bibliography, "å‚è€ƒæ–‡çŒ®åº”è¯¥åŒ…å«æ ‡é¢˜"
            
        print("âœ… å¼•ç”¨ç®¡ç†å™¨æµ‹è¯•æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âŒ å¼•ç”¨ç®¡ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_quality_enhanced_generator():
    """æµ‹è¯•è´¨é‡å¢å¼ºç”Ÿæˆå™¨ï¼ˆé›†æˆæµ‹è¯•ï¼‰"""
    print("\n" + "=" * 60)
    print("6. æµ‹è¯•è´¨é‡å¢å¼ºç”Ÿæˆå™¨ï¼ˆé›†æˆæµ‹è¯•ï¼‰")
    print("=" * 60)
    
    try:
        from src.generator.quality_enhancement import QualityEnhancedGenerator
        
        # åˆ›å»ºç”Ÿæˆå™¨
        generator = QualityEnhancedGenerator(citation_style='APA')
        
        # æ¨¡æ‹Ÿæ£€ç´¢ç»“æœ
        mock_results = [
            {
                'content': 'Transformer architecture revolutionized NLP by introducing self-attention mechanisms that allow parallel processing of sequences.',
                'metadata': {
                    'paper_id': '1706.03762',
                    'title': 'Attention Is All You Need',
                    'authors': ['Ashish Vaswani', 'Noam Shazeer'],
                    'published': '2017-06-12',
                    'section_type': 'abstract',
                    'has_formulas': True,
                    'has_citations': True
                },
                'combined_score': 0.9,
                'relevance_score': 0.9
            },
            {
                'content': 'BERT uses bidirectional encoder representations from transformers, demonstrating significant improvements in language understanding tasks.',
                'metadata': {
                    'paper_id': '1810.04805',
                    'title': 'BERT: Pre-training of Deep Bidirectional Transformers',
                    'authors': ['Jacob Devlin', 'Ming-Wei Chang'],
                    'published': '2018-10-11',
                    'section_type': 'results',
                    'has_citations': True
                },
                'combined_score': 0.8,
                'relevance_score': 0.8
            },
            {
                'content': 'GPT models demonstrate the power of autoregressive language modeling for various downstream tasks.',
                'metadata': {
                    'paper_id': '1810.04855',
                    'title': 'Improving Language Understanding by Generative Pre-Training',
                    'authors': ['Alec Radford', 'Karthik Narasimhan'],
                    'published': '2018-06-11',
                    'section_type': 'methodology',
                    'has_formulas': False,
                    'has_citations': True
                },
                'combined_score': 0.7,
                'relevance_score': 0.7
            }
        ]
        
        # æµ‹è¯•ä¸åŒæŸ¥è¯¢æ„å›¾
        test_cases = [
            ("What is the transformer architecture?", "definition"),
            ("Compare BERT and GPT models", "comparison"),
            ("How does self-attention work?", "methodology"),
            ("Recent advances in transformer models", "recent_work")
        ]
        
        for query, intent in test_cases:
            print(f"\næµ‹è¯•æŸ¥è¯¢: {query} (æ„å›¾: {intent})")
            
            result = generator.generate_enhanced_answer(query, intent, mock_results)
            
            # éªŒè¯ç»“æœç»“æ„
            assert 'answer' in result, "ç»“æœåº”è¯¥åŒ…å«ç­”æ¡ˆ"
            assert 'context_info' in result, "ç»“æœåº”è¯¥åŒ…å«ä¸Šä¸‹æ–‡ä¿¡æ¯"
            assert 'citations' in result, "ç»“æœåº”è¯¥åŒ…å«å¼•ç”¨"
            assert 'quality_metrics' in result, "ç»“æœåº”è¯¥åŒ…å«è´¨é‡æŒ‡æ ‡"
            
            context_info = result['context_info']
            quality_metrics = result['quality_metrics']
            
            print(f"   âœ… ç­”æ¡ˆé•¿åº¦: {len(result['answer'])} å­—ç¬¦")
            print(f"   âœ… ç½®ä¿¡åº¦: {context_info['confidence_level']:.3f}")
            print(f"   âœ… æºæ•°é‡: {context_info['source_count']}")
            print(f"   âœ… å¼•ç”¨æ•°é‡: {len(result['citations'])}")
            print(f"   âœ… æ•´ä½“è´¨é‡: {quality_metrics['overall_quality']:.3f}")
            print(f"   âœ… å»ºè®®: {quality_metrics['recommendation']}")
            
            if result.get('fact_check'):
                print(f"   âœ… äº‹å®æ ¸æŸ¥: {len(result['fact_check'])} é¡¹")
            
            # éªŒè¯è´¨é‡æŒ‡æ ‡èŒƒå›´
            assert 0 <= context_info['confidence_level'] <= 1, "ç½®ä¿¡åº¦åº”è¯¥åœ¨0-1ä¹‹é—´"
            assert context_info['source_count'] > 0, "åº”è¯¥æœ‰æºæ–‡æ¡£"
            assert 0 <= quality_metrics['overall_quality'] <= 1, "è´¨é‡åˆ†æ•°åº”è¯¥åœ¨0-1ä¹‹é—´"
        
        # æµ‹è¯•ä½è´¨é‡åœºæ™¯
        print(f"\næµ‹è¯•ä½è´¨é‡åœºæ™¯:")
        low_quality_results = [
            {
                'content': 'Very short content.',
                'metadata': {
                    'paper_id': 'low_quality',
                    'title': 'Low Quality Paper',
                    'section_type': 'content'
                },
                'combined_score': 0.1,
                'relevance_score': 0.1
            }
        ]
        
        low_quality_result = generator.generate_enhanced_answer(
            "Test low quality query", "general", low_quality_results
        )
        
        if low_quality_result.get('quality_warning'):
            print("   âœ… æ­£ç¡®æ£€æµ‹åˆ°ä½è´¨é‡åœºæ™¯")
        else:
            print("   âš ï¸  ä½è´¨é‡æ£€æµ‹å¯èƒ½éœ€è¦è°ƒæ•´é˜ˆå€¼")
        
        print("âœ… è´¨é‡å¢å¼ºç”Ÿæˆå™¨é›†æˆæµ‹è¯•æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âŒ è´¨é‡å¢å¼ºç”Ÿæˆå™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_performance():
    """æµ‹è¯•æ€§èƒ½"""
    print("\n" + "=" * 60)
    print("7. æ€§èƒ½æµ‹è¯•")
    print("=" * 60)
    
    try:
        from src.generator.quality_enhancement import QualityEnhancedGenerator
        
        generator = QualityEnhancedGenerator()
        
        # ç®€å•çš„æ€§èƒ½æµ‹è¯•æ•°æ®
        mock_results = [
            {
                'content': f'Test content {i} about machine learning and artificial intelligence.',
                'metadata': {
                    'paper_id': f'test_{i}',
                    'title': f'Test Paper {i}',
                    'section_type': 'content'
                },
                'combined_score': 0.5,
                'relevance_score': 0.5
            }
            for i in range(10)
        ]
        
        # æµ‹è¯•å¤„ç†æ—¶é—´
        start_time = time.time()
        result = generator.generate_enhanced_answer(
            "What is machine learning?", "definition", mock_results
        )
        processing_time = time.time() - start_time
        
        print(f"âœ… å¤„ç†æ—¶é—´: {processing_time:.3f} ç§’")
        print(f"âœ… å¤„ç†äº† {len(mock_results)} ä¸ªæ–‡æ¡£")
        print(f"âœ… å¹³å‡æ¯æ–‡æ¡£: {processing_time/len(mock_results):.4f} ç§’")
        
        # éªŒè¯åœ¨åˆç†æ—¶é—´å†…å®Œæˆ
        assert processing_time < 10, "å¤„ç†æ—¶é—´åº”è¯¥åœ¨10ç§’å†…"
        
        return True
        
    except Exception as e:
        print(f"âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("è´¨é‡å¢å¼ºæ¨¡å—æµ‹è¯•å¼€å§‹")
    print("ğŸ” æµ‹è¯• src/generator/quality_enhancement.py")
    
    test_results = []
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    tests = [
        ("æ¨¡å—å¯¼å…¥", test_imports),
        ("ä¸Šä¸‹æ–‡ä¼˜åŒ–å™¨", test_context_optimizer),
        ("æç¤ºè¯å·¥ç¨‹å¸ˆ", test_prompt_engineer),
        ("äº‹å®æ ¸æŸ¥å™¨", test_fact_checker),
        ("å¼•ç”¨ç®¡ç†å™¨", test_citation_manager),
        ("è´¨é‡å¢å¼ºç”Ÿæˆå™¨", test_quality_enhanced_generator),
        ("æ€§èƒ½æµ‹è¯•", test_performance)
    ]
    
    for test_name, test_func in tests:
        try:
            result = test_func()
            test_results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name} æµ‹è¯•å‡ºç°å¼‚å¸¸: {e}")
            test_results.append((test_name, False))
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 60)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    
    passed = 0
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\næ€»ç»“: {passed}/{total} é¡¹æµ‹è¯•é€šè¿‡ ({passed/total*100:.1f}%)")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼quality_enhancement.py æ¨¡å—å·¥ä½œæ­£å¸¸")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)