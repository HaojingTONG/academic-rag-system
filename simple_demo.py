#!/usr/bin/env python3
"""
ç®€å•çš„æ¼”ç¤ºç¨‹åº - æ”¶é›†è®ºæ–‡å¹¶æµ‹è¯•åŸºæœ¬åŠŸèƒ½
"""

import arxiv
import os
import requests
from pathlib import Path
from tqdm import tqdm
import time

def collect_sample_papers(num_papers=5):
    """æ”¶é›†ç¤ºä¾‹è®ºæ–‡"""
    print(f"ğŸ“š å¼€å§‹æ”¶é›†{num_papers}ç¯‡AIè®ºæ–‡...")
    
    # åˆ›å»ºå­˜å‚¨ç›®å½•
    pdf_dir = Path("data/raw_papers")
    pdf_dir.mkdir(exist_ok=True)
    
    # æœç´¢è®ºæ–‡
    client = arxiv.Client()
    search = arxiv.Search(
        query="cat:cs.AI AND (transformer OR attention OR BERT)",
        max_results=num_papers,
        sort_by=arxiv.SortCriterion.Relevance
    )
    
    papers = []
    for i, result in enumerate(tqdm(client.results(search), desc="æ”¶é›†è®ºæ–‡")):
        paper_data = {
            "id": result.entry_id.split('/')[-1],
            "title": result.title,
            "authors": [str(author) for author in result.authors],
            "abstract": result.summary,
            "published": result.published.strftime("%Y-%m-%d"),
            "pdf_url": result.pdf_url
        }
        
        # ä¸‹è½½PDF
        pdf_path = pdf_dir / f"{paper_data['id']}.pdf"
        try:
            if not pdf_path.exists():
                print(f"ğŸ“„ ä¸‹è½½: {paper_data['title'][:50]}...")
                response = requests.get(result.pdf_url, timeout=30)
                response.raise_for_status()
                
                with open(pdf_path, 'wb') as f:
                    f.write(response.content)
                
                paper_data["local_path"] = str(pdf_path)
                time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            continue
        
        papers.append(paper_data)
        
        if len(papers) >= num_papers:
            break
    
    print(f"âœ… æˆåŠŸæ”¶é›†{len(papers)}ç¯‡è®ºæ–‡")
    
    # ä¿å­˜è®ºæ–‡ä¿¡æ¯
    import json
    with open("data/papers_info.json", "w", encoding="utf-8") as f:
        json.dump(papers, f, ensure_ascii=False, indent=2)
    
    return papers

def test_embedding():
    """æµ‹è¯•åµŒå…¥åŠŸèƒ½"""
    print("\nğŸ”¢ æµ‹è¯•åµŒå…¥æ¨¡å‹...")
    
    try:
        from sentence_transformers import SentenceTransformer
        import torch
        
        # åŠ è½½æ¨¡å‹
        device = "mps" if torch.backends.mps.is_available() else "cpu"
        model = SentenceTransformer("all-MiniLM-L6-v2", device=device)
        
        # æµ‹è¯•æ–‡æœ¬
        test_texts = [
            "Transformer architecture with attention mechanism",
            "Deep learning neural networks",
            "Natural language processing"
        ]
        
        # ç”ŸæˆåµŒå…¥
        embeddings = model.encode(test_texts)
        print(f"âœ… åµŒå…¥ç»´åº¦: {embeddings.shape}")
        print(f"âœ… ä½¿ç”¨è®¾å¤‡: {device}")
        
        return True
    except Exception as e:
        print(f"âŒ åµŒå…¥æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_ollama():
    """æµ‹è¯•Ollamaè¿æ¥"""
    print("\nğŸ¤– æµ‹è¯•æœ¬åœ°LLM...")
    
    try:
        import subprocess
        result = subprocess.run(["ollama", "list"], capture_output=True, text=True)
        
        if result.returncode == 0:
            print("âœ… Ollamaè¿æ¥æˆåŠŸ")
            print("å·²å®‰è£…çš„æ¨¡å‹:")
            print(result.stdout)
            return True
        else:
            print("âŒ Ollamaè¿æ¥å¤±è´¥")
            return False
    except Exception as e:
        print(f"âŒ Ollamaæµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æ¼”ç¤ºç¨‹åº"""
    print("ğŸ§ª å¼€å§‹ç³»ç»ŸåŠŸèƒ½æµ‹è¯•...")
    print("="*50)
    
    # 1. æ”¶é›†è®ºæ–‡
    papers = collect_sample_papers(5)
    
    # 2. æµ‹è¯•åµŒå…¥
    embedding_ok = test_embedding()
    
    # 3. æµ‹è¯•LLM
    llm_ok = test_ollama()
    
    # ç»“æœæ€»ç»“
    print("\n" + "="*50)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    print(f"ğŸ“š è®ºæ–‡æ”¶é›†: {'âœ…' if len(papers) > 0 else 'âŒ'} ({len(papers)}ç¯‡)")
    print(f"ğŸ”¢ åµŒå…¥æ¨¡å‹: {'âœ…' if embedding_ok else 'âŒ'}")
    print(f"ğŸ¤– æœ¬åœ°LLM: {'âœ…' if llm_ok else 'âŒ'}")
    
    if len(papers) > 0 and embedding_ok:
        print("\nğŸ‰ åŸºç¡€åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        print("ä¸‹ä¸€æ­¥å¯ä»¥è¿è¡Œå®Œæ•´çš„RAGç³»ç»Ÿ")
    else:
        print("\nâš ï¸ éƒ¨åˆ†åŠŸèƒ½éœ€è¦ä¿®å¤")

if __name__ == "__main__":
    main()
