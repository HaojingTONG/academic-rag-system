# src/processor/pdf_processor.py
"""
PDFå…¨æ–‡å¤„ç†æ¨¡å— - æå–å­¦æœ¯è®ºæ–‡çš„å®Œæ•´å†…å®¹
æ”¯æŒæ™ºèƒ½ç« èŠ‚è¯†åˆ«ã€å†…å®¹æ¸…ç†å’Œç»“æ„åŒ–å¤„ç†
"""

import fitz  # PyMuPDF
import re
from typing import List, Dict, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass
import logging

@dataclass
class PDFSection:
    """PDFç« èŠ‚æ•°æ®ç»“æ„"""
    title: str
    content: str
    section_type: str  # abstract, introduction, method, experiment, result, conclusion, reference
    page_range: Tuple[int, int]
    confidence: float  # è¯†åˆ«ç½®ä¿¡åº¦

@dataclass 
class PDFContent:
    """PDFå®Œæ•´å†…å®¹æ•°æ®ç»“æ„"""
    title: str
    abstract: str
    sections: List[PDFSection]
    total_pages: int
    total_words: int
    has_formulas: bool
    has_tables: bool
    has_figures: bool
    language: str  # en, zh, etc.
    
class AcademicPDFProcessor:
    """å­¦æœ¯è®ºæ–‡PDFå¤„ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–PDFå¤„ç†å™¨"""
        # å¸¸è§ç« èŠ‚æ ‡é¢˜æ¨¡å¼ï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼‰
        self.section_patterns = {
            'abstract': [
                r'^\s*abstract\s*$',
                r'^\s*æ‘˜\s*è¦\s*$',
                r'^\s*summary\s*$'
            ],
            'introduction': [
                r'^\s*1\.?\s*introduction\s*$',
                r'^\s*introduction\s*$',
                r'^\s*1\.?\s*å¼•\s*è¨€\s*$',
                r'^\s*å¼•\s*è¨€\s*$'
            ],
            'method': [
                r'^\s*\d+\.?\s*method[s]?\s*$',
                r'^\s*\d+\.?\s*approach\s*$',
                r'^\s*\d+\.?\s*methodology\s*$',
                r'^\s*æ–¹\s*æ³•\s*$',
                r'^\s*\d+\.?\s*æ–¹\s*æ³•\s*$'
            ],
            'experiment': [
                r'^\s*\d+\.?\s*experiment[s]?\s*$',
                r'^\s*\d+\.?\s*evaluation\s*$',
                r'^\s*\d+\.?\s*å®\s*éªŒ\s*$',
                r'^\s*å®\s*éªŒ\s*$'
            ],
            'result': [
                r'^\s*\d+\.?\s*result[s]?\s*$',
                r'^\s*\d+\.?\s*finding[s]?\s*$',
                r'^\s*ç»“\s*æœ\s*$',
                r'^\s*\d+\.?\s*ç»“\s*æœ\s*$'
            ],
            'conclusion': [
                r'^\s*\d+\.?\s*conclusion[s]?\s*$',
                r'^\s*\d+\.?\s*discussion\s*$',
                r'^\s*ç»“\s*è®º\s*$',
                r'^\s*\d+\.?\s*ç»“\s*è®º\s*$'
            ],
            'reference': [
                r'^\s*reference[s]?\s*$',
                r'^\s*bibliography\s*$',
                r'^\s*å‚\s*è€ƒ\s*æ–‡\s*çŒ®\s*$'
            ]
        }
        
        # ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
        self.compiled_patterns = {}
        for section_type, patterns in self.section_patterns.items():
            self.compiled_patterns[section_type] = [
                re.compile(pattern, re.IGNORECASE) for pattern in patterns
            ]
    
    def extract_pdf_content(self, pdf_path: str) -> Optional[PDFContent]:
        """æå–PDFå®Œæ•´å†…å®¹"""
        try:
            print(f"ğŸ“„ å¤„ç†PDF: {Path(pdf_path).name}")
            
            # æ‰“å¼€PDFæ–‡æ¡£
            doc = fitz.open(pdf_path)
            
            # æå–åŸºæœ¬ä¿¡æ¯
            metadata = doc.metadata
            total_pages = doc.page_count
            
            print(f"   ğŸ“Š æ€»é¡µæ•°: {total_pages}")
            
            # æå–å…¨æ–‡å†…å®¹
            full_text = ""
            page_texts = []
            
            for page_num in range(total_pages):
                page = doc[page_num]
                page_text = page.get_text()
                page_texts.append((page_num + 1, page_text))
                full_text += page_text + "\n"
            
            doc.close()
            
            if not full_text.strip():
                print("   âŒ PDFå†…å®¹ä¸ºç©º")
                return None
            
            # åˆ†ææ–‡æ¡£ç‰¹å¾
            has_formulas = self._detect_formulas(full_text)
            has_tables = self._detect_tables(full_text)  
            has_figures = self._detect_figures(full_text)
            language = self._detect_language(full_text)
            total_words = len(full_text.split())
            
            print(f"   ğŸ“ æ€»è¯æ•°: {total_words}")
            print(f"   ğŸ§® åŒ…å«å…¬å¼: {'æ˜¯' if has_formulas else 'å¦'}")
            print(f"   ğŸ“Š åŒ…å«è¡¨æ ¼: {'æ˜¯' if has_tables else 'å¦'}")  
            print(f"   ğŸ–¼ï¸ åŒ…å«å›¾ç‰‡: {'æ˜¯' if has_figures else 'å¦'}")
            print(f"   ğŸŒ è¯­è¨€: {language}")
            
            # æå–æ ‡é¢˜
            title = self._extract_title(page_texts[0][1] if page_texts else "")
            print(f"   ğŸ“‹ æ ‡é¢˜: {title[:50]}...")
            
            # æå–æ‘˜è¦
            abstract = self._extract_abstract(full_text)
            print(f"   ğŸ“„ æ‘˜è¦: {len(abstract)} å­—ç¬¦")
            
            # æ™ºèƒ½ç« èŠ‚åˆ†å‰²
            sections = self._extract_sections(page_texts)
            print(f"   ğŸ“‘ è¯†åˆ«ç« èŠ‚: {len(sections)} ä¸ª")
            
            for section in sections:
                print(f"      - {section.section_type}: {section.title[:30]}... ({len(section.content)} å­—ç¬¦)")
            
            return PDFContent(
                title=title,
                abstract=abstract,
                sections=sections,
                total_pages=total_pages,
                total_words=total_words,
                has_formulas=has_formulas,
                has_tables=has_tables,
                has_figures=has_figures,
                language=language
            )
            
        except Exception as e:
            print(f"   âŒ PDFå¤„ç†å¤±è´¥: {e}")
            return None
    
    def _extract_title(self, first_page_text: str) -> str:
        """æå–è®ºæ–‡æ ‡é¢˜"""
        lines = first_page_text.split('\n')
        
        # å¯»æ‰¾æœ€å¯èƒ½çš„æ ‡é¢˜è¡Œ
        for i, line in enumerate(lines[:20]):  # åªæ£€æŸ¥å‰20è¡Œ
            line = line.strip()
            if len(line) > 10 and len(line) < 200:  # æ ‡é¢˜é•¿åº¦åˆç†
                # æ’é™¤å¸¸è§çš„éæ ‡é¢˜å†…å®¹
                if not any(exclude in line.lower() for exclude in 
                          ['arxiv:', 'doi:', 'page', 'abstract', 'www.', 'http']):
                    return line
        
        return "Unknown Title"
    
    def _extract_abstract(self, full_text: str) -> str:
        """æå–è®ºæ–‡æ‘˜è¦"""
        # æŸ¥æ‰¾Abstractç« èŠ‚
        abstract_pattern = r'(?i)abstract\s*[:\-]?\s*\n(.*?)(?=\n\s*(?:1\.?\s*introduction|keywords|key\s*words|\n\s*\n))'
        
        match = re.search(abstract_pattern, full_text, re.DOTALL)
        if match:
            abstract = match.group(1).strip()
            # æ¸…ç†æ‘˜è¦å†…å®¹
            abstract = re.sub(r'\s+', ' ', abstract)  # è§„èŒƒåŒ–ç©ºç™½å­—ç¬¦
            abstract = abstract.replace('\n', ' ')
            return abstract[:2000]  # é™åˆ¶é•¿åº¦
        
        return ""
    
    def _extract_sections(self, page_texts: List[Tuple[int, str]]) -> List[PDFSection]:
        """æ™ºèƒ½æå–ç« èŠ‚å†…å®¹"""
        sections = []
        full_text = "\n".join([text for _, text in page_texts])
        
        # å¯»æ‰¾ç« èŠ‚åˆ†ç•Œç‚¹
        section_boundaries = []
        
        for page_num, page_text in page_texts:
            lines = page_text.split('\n')
            
            for line_num, line in enumerate(lines):
                line_clean = line.strip()
                if len(line_clean) < 3 or len(line_clean) > 100:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦åŒ¹é…ç« èŠ‚æ¨¡å¼
                for section_type, patterns in self.compiled_patterns.items():
                    for pattern in patterns:
                        if pattern.match(line_clean):
                            confidence = self._calculate_section_confidence(line_clean, section_type)
                            section_boundaries.append({
                                'page': page_num,
                                'line': line_num,
                                'title': line_clean,
                                'type': section_type,
                                'confidence': confidence
                            })
                            break
        
        # æŒ‰é¡µé¢å’Œè¡Œå·æ’åº
        section_boundaries.sort(key=lambda x: (x['page'], x['line']))
        
        # æå–ç« èŠ‚å†…å®¹
        for i, boundary in enumerate(section_boundaries):
            if boundary['confidence'] < 0.5:  # è¿‡æ»¤ä½ç½®ä¿¡åº¦çš„è¯†åˆ«
                continue
                
            # ç¡®å®šç« èŠ‚å†…å®¹èŒƒå›´
            start_page = boundary['page']
            start_line = boundary['line']
            
            if i + 1 < len(section_boundaries):
                end_page = section_boundaries[i + 1]['page']
                end_line = section_boundaries[i + 1]['line']
            else:
                end_page = page_texts[-1][0]
                end_line = float('inf')
            
            # æå–ç« èŠ‚å†…å®¹
            content = self._extract_section_content(
                page_texts, start_page, start_line, end_page, end_line
            )
            
            if content.strip():
                section = PDFSection(
                    title=boundary['title'],
                    content=content,
                    section_type=boundary['type'],
                    page_range=(start_page, end_page),
                    confidence=boundary['confidence']
                )
                sections.append(section)
        
        return sections
    
    def _extract_section_content(self, page_texts: List[Tuple[int, str]], 
                                start_page: int, start_line: int,
                                end_page: int, end_line: int) -> str:
        """æå–æŒ‡å®šèŒƒå›´çš„ç« èŠ‚å†…å®¹"""
        content_lines = []
        
        for page_num, page_text in page_texts:
            if page_num < start_page or page_num > end_page:
                continue
                
            lines = page_text.split('\n')
            
            for line_num, line in enumerate(lines):
                # è·³è¿‡ç« èŠ‚æ ‡é¢˜è¡Œ
                if page_num == start_page and line_num <= start_line:
                    continue
                if page_num == end_page and line_num >= end_line:
                    break
                    
                content_lines.append(line)
        
        content = '\n'.join(content_lines)
        
        # æ¸…ç†å†…å®¹
        content = self._clean_text_content(content)
        
        return content
    
    def _clean_text_content(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬å†…å®¹"""
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        text = re.sub(r'\s+', ' ', text)
        
        # ç§»é™¤é¡µç å’Œé¡µçœ‰é¡µè„š
        text = re.sub(r'\n\s*\d+\s*\n', '\n', text)
        
        # ç§»é™¤è¿‡çŸ­çš„è¡Œï¼ˆå¯èƒ½æ˜¯æ ¼å¼å™ªå£°ï¼‰
        lines = text.split('\n')
        cleaned_lines = []
        for line in lines:
            line = line.strip()
            if len(line) > 3:  # ä¿ç•™æœ‰æ„ä¹‰çš„å†…å®¹
                cleaned_lines.append(line)
        
        return '\n'.join(cleaned_lines)
    
    def _calculate_section_confidence(self, line: str, section_type: str) -> float:
        """è®¡ç®—ç« èŠ‚è¯†åˆ«ç½®ä¿¡åº¦"""
        confidence = 0.5  # åŸºç¡€ç½®ä¿¡åº¦
        
        # å¦‚æœæœ‰æ•°å­—ç¼–å·ï¼Œå¢åŠ ç½®ä¿¡åº¦
        if re.match(r'^\s*\d+\.?\s*', line):
            confidence += 0.2
        
        # å¦‚æœæ ¼å¼è§„æ•´ï¼Œå¢åŠ ç½®ä¿¡åº¦
        if line.isupper() or line.istitle():
            confidence += 0.1
        
        # æ ¹æ®ç« èŠ‚ç±»å‹è°ƒæ•´
        if section_type == 'abstract' and 'abstract' in line.lower():
            confidence += 0.3
        elif section_type == 'reference' and any(word in line.lower() 
                                               for word in ['reference', 'bibliography']):
            confidence += 0.3
        
        return min(confidence, 1.0)
    
    def _detect_formulas(self, text: str) -> bool:
        """æ£€æµ‹æ–‡æ¡£æ˜¯å¦åŒ…å«æ•°å­¦å…¬å¼"""
        formula_indicators = [
            r'\$.*\$',  # LaTeXå…¬å¼
            r'\\[a-zA-Z]+\{',  # LaTeXå‘½ä»¤
            r'âˆ‘|âˆ|âˆ«|âˆ‚|âˆ‡|â‰ˆ|â‰¤|â‰¥|Â±|Î±|Î²|Î³|Î´|Îµ|Î¸|Î»|Î¼|Ï€|Ïƒ|Ï†|Ïˆ|Ï‰',  # æ•°å­¦ç¬¦å·
            r'[a-zA-Z]\s*[=]\s*[a-zA-Z0-9\+\-\*/\(\)]+',  # ç®€å•ç­‰å¼
        ]
        
        for pattern in formula_indicators:
            if re.search(pattern, text):
                return True
        return False
    
    def _detect_tables(self, text: str) -> bool:
        """æ£€æµ‹æ–‡æ¡£æ˜¯å¦åŒ…å«è¡¨æ ¼"""
        table_indicators = [
            r'table\s+\d+',
            r'è¡¨\s*\d+',
            r'\|.*\|.*\|',  # ç®€å•çš„è¡¨æ ¼æ ¼å¼
            r'(\w+\s+){3,}\n(\w+\s+){3,}',  # åˆ—å¯¹é½çš„æ•°æ®
        ]
        
        for pattern in table_indicators:
            if re.search(pattern, text, re.IGNORECASE):
                return True
        return False
    
    def _detect_figures(self, text: str) -> bool:
        """æ£€æµ‹æ–‡æ¡£æ˜¯å¦åŒ…å«å›¾ç‰‡"""
        figure_indicators = [
            r'figure\s+\d+',
            r'fig\.\s*\d+',
            r'å›¾\s*\d+',
            r'illustration\s+\d+',
        ]
        
        for pattern in figure_indicators:
            if re.search(pattern, text, re.IGNORECASE):
                return True
        return False
    
    def _detect_language(self, text: str) -> str:
        """æ£€æµ‹æ–‡æ¡£ä¸»è¦è¯­è¨€"""
        # ç®€å•çš„è¯­è¨€æ£€æµ‹
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        english_words = len(re.findall(r'\b[a-zA-Z]+\b', text))
        
        if chinese_chars > english_words * 0.5:
            return 'zh'
        else:
            return 'en'

def test_pdf_processor():
    """æµ‹è¯•PDFå¤„ç†å™¨"""
    processor = AcademicPDFProcessor()
    
    # æµ‹è¯•ä¸€ä¸ªPDFæ–‡ä»¶
    pdf_files = list(Path("data/raw_papers").glob("*.pdf"))
    if pdf_files:
        test_file = pdf_files[0]
        print(f"ğŸ§ª æµ‹è¯•PDFå¤„ç†å™¨: {test_file.name}")
        
        content = processor.extract_pdf_content(str(test_file))
        if content:
            print(f"âœ… å¤„ç†æˆåŠŸ!")
            print(f"   æ ‡é¢˜: {content.title}")
            print(f"   ç« èŠ‚æ•°: {len(content.sections)}")
            print(f"   æ€»é¡µæ•°: {content.total_pages}")
            print(f"   æ€»è¯æ•°: {content.total_words}")
        else:
            print("âŒ å¤„ç†å¤±è´¥")
    else:
        print("âŒ æœªæ‰¾åˆ°PDFæ–‡ä»¶")

if __name__ == "__main__":
    test_pdf_processor()