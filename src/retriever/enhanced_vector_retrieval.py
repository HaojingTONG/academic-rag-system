"""
å¢å¼ºå‹å‘é‡æ£€ç´¢æ¨¡å—
å®ç°é«˜çº§å‘é‡æ£€ç´¢åŠŸèƒ½ï¼ŒåŒ…æ‹¬ç›¸ä¼¼åº¦é˜ˆå€¼è¿‡æ»¤å’Œæ™ºèƒ½Top-Ké€‰æ‹©
"""

from typing import List, Dict, Optional, Tuple, Union
import numpy as np
from dataclasses import dataclass
import time

@dataclass 
class RetrievalConfig:
    """å‘é‡æ£€ç´¢é…ç½®"""
    # Top-Kå‚æ•°
    default_top_k: int = 5
    max_top_k: int = 50
    min_top_k: int = 1
    
    # ç›¸ä¼¼åº¦é˜ˆå€¼
    similarity_threshold: float = 0.3  # ä½™å¼¦ç›¸ä¼¼åº¦é˜ˆå€¼
    strict_threshold: float = 0.5      # ä¸¥æ ¼é˜ˆå€¼
    loose_threshold: float = 0.1       # å®½æ¾é˜ˆå€¼
    
    # è·ç¦»åº¦é‡ 
    distance_metric: str = "cosine"    # cosine, euclidean, dot_product
    
    # æ™ºèƒ½Kå€¼è°ƒæ•´
    enable_adaptive_k: bool = True
    relevance_drop_threshold: float = 0.15  # ç›¸ä¼¼åº¦æ˜¾è‘—ä¸‹é™é˜ˆå€¼
    
    # ç»“æœå¤šæ ·æ€§
    enable_diversity: bool = False
    diversity_threshold: float = 0.8   # æ–‡æ¡£é—´ç›¸ä¼¼åº¦é˜ˆå€¼

@dataclass
class RetrievalResult:
    """æ£€ç´¢ç»“æœ"""
    document: str
    metadata: Dict
    similarity_score: float
    distance: float
    rank: int
    is_above_threshold: bool = True

class EnhancedVectorRetriever:
    """å¢å¼ºå‹å‘é‡æ£€ç´¢å™¨"""
    
    def __init__(self, vector_store, config: RetrievalConfig = None):
        """
        åˆå§‹åŒ–å¢å¼ºå‘é‡æ£€ç´¢å™¨
        
        Args:
            vector_store: å‘é‡å­˜å‚¨å®ä¾‹
            config: æ£€ç´¢é…ç½®
        """
        self.vector_store = vector_store
        self.config = config or RetrievalConfig()
        
        print(f"ğŸ” åˆå§‹åŒ–å¢å¼ºå‘é‡æ£€ç´¢å™¨")
        print(f"   - é»˜è®¤Top-K: {self.config.default_top_k}")
        print(f"   - ç›¸ä¼¼åº¦é˜ˆå€¼: {self.config.similarity_threshold}")
        print(f"   - è·ç¦»åº¦é‡: {self.config.distance_metric}")
        print(f"   - è‡ªé€‚åº”Kå€¼: {self.config.enable_adaptive_k}")
    
    def search(self, 
               query: str,
               top_k: Optional[int] = None,
               similarity_threshold: Optional[float] = None,
               filter_metadata: Optional[Dict] = None,
               return_scores: bool = True,
               enable_adaptive_k: Optional[bool] = None,
               enable_diversity: Optional[bool] = None) -> List[RetrievalResult]:
        """
        å¢å¼ºå‘é‡æ£€ç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡ï¼ˆNoneä½¿ç”¨é»˜è®¤å€¼ï¼‰
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆNoneä½¿ç”¨é…ç½®é»˜è®¤å€¼ï¼‰  
            filter_metadata: å…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶
            return_scores: æ˜¯å¦è¿”å›åˆ†æ•°
            enable_adaptive_k: æ˜¯å¦å¯ç”¨è‡ªé€‚åº”Kå€¼è°ƒæ•´
            enable_diversity: æ˜¯å¦å¯ç”¨ç»“æœå¤šæ ·æ€§
            
        Returns:
            List[RetrievalResult]: æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        
        # å‚æ•°å¤„ç†
        if top_k is None:
            top_k = self.config.default_top_k
        if similarity_threshold is None:
            similarity_threshold = self.config.similarity_threshold
        if enable_adaptive_k is None:
            enable_adaptive_k = self.config.enable_adaptive_k
        if enable_diversity is None:
            enable_diversity = self.config.enable_diversity
            
        # é™åˆ¶top_kèŒƒå›´
        top_k = max(self.config.min_top_k, min(top_k, self.config.max_top_k))
        
        start_time = time.time()
        print(f"ğŸ” å‘é‡æ£€ç´¢: \"{query[:50]}...\"")
        print(f"   - Top-K: {top_k}")
        print(f"   - ç›¸ä¼¼åº¦é˜ˆå€¼: {similarity_threshold}")
        
        # 1. æ‰§è¡Œå‘é‡æœç´¢ï¼ˆè·å–æ›´å¤šå€™é€‰ç»“æœç”¨äºåç»­è¿‡æ»¤ï¼‰
        candidate_k = max(top_k * 2, 20) if enable_adaptive_k else top_k
        
        try:
            raw_results = self.vector_store.search(
                query=query,
                top_k=candidate_k,
                filter_metadata=filter_metadata
            )
        except Exception as e:
            print(f"âŒ å‘é‡æœç´¢å¤±è´¥: {e}")
            return []
        
        # 2. è§£æåŸå§‹ç»“æœ
        documents = raw_results.get("documents", [])
        metadatas = raw_results.get("metadatas", [])
        distances = raw_results.get("distances", [])
        
        if not documents:
            print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•åŒ¹é…ç»“æœ")
            return []
        
        # 3. è½¬æ¢ä¸ºRetrievalResultå¯¹è±¡
        results = []
        for i, (doc, metadata, distance) in enumerate(zip(documents, metadatas, distances)):
            # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆå‡è®¾ä½¿ç”¨ä½™å¼¦è·ç¦»ï¼‰
            similarity_score = self._distance_to_similarity(distance, self.config.distance_metric)
            
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é˜ˆå€¼
            is_above_threshold = similarity_score >= similarity_threshold
            
            result = RetrievalResult(
                document=doc,
                metadata=metadata or {},
                similarity_score=similarity_score,
                distance=distance,
                rank=i + 1,
                is_above_threshold=is_above_threshold
            )
            results.append(result)
        
        # 4. ç›¸ä¼¼åº¦é˜ˆå€¼è¿‡æ»¤
        filtered_results = self._apply_similarity_threshold(results, similarity_threshold)
        
        # 5. æ™ºèƒ½Top-Kè°ƒæ•´
        if enable_adaptive_k:
            final_results = self._adaptive_top_k_selection(filtered_results, top_k)
        else:
            final_results = filtered_results[:top_k]
        
        # 6. ç»“æœå¤šæ ·æ€§å¤„ç†
        if enable_diversity and len(final_results) > 1:
            final_results = self._apply_diversity_filter(final_results)
        
        # 7. é‡æ–°æ’åºç»“æœ
        final_results = sorted(final_results, key=lambda x: x.similarity_score, reverse=True)
        for i, result in enumerate(final_results):
            result.rank = i + 1
        
        retrieval_time = time.time() - start_time
        
        # 8. è¾“å‡ºæ£€ç´¢ç»Ÿè®¡
        self._print_retrieval_stats(query, final_results, retrieval_time, similarity_threshold)
        
        return final_results
    
    def _distance_to_similarity(self, distance: float, metric: str) -> float:
        """å°†è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°"""
        if metric == "cosine":
            # ä½™å¼¦è·ç¦»è½¬æ¢ä¸ºä½™å¼¦ç›¸ä¼¼åº¦
            return max(0.0, 1.0 - distance)
        elif metric == "euclidean":
            # æ¬§æ°è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦ï¼ˆç®€å•çš„å½’ä¸€åŒ–æ–¹æ³•ï¼‰
            return 1.0 / (1.0 + distance)
        elif metric == "dot_product":
            # ç‚¹ç§¯å·²ç»æ˜¯ç›¸ä¼¼åº¦åº¦é‡
            return distance
        else:
            # é»˜è®¤å‡è®¾æ˜¯ä½™å¼¦è·ç¦»
            return max(0.0, 1.0 - distance)
    
    def _apply_similarity_threshold(self, 
                                   results: List[RetrievalResult], 
                                   threshold: float) -> List[RetrievalResult]:
        """åº”ç”¨ç›¸ä¼¼åº¦é˜ˆå€¼è¿‡æ»¤"""
        filtered_results = []
        below_threshold_count = 0
        
        for result in results:
            if result.similarity_score >= threshold:
                filtered_results.append(result)
            else:
                below_threshold_count += 1
                result.is_above_threshold = False
        
        if below_threshold_count > 0:
            print(f"ğŸ“Š ç›¸ä¼¼åº¦è¿‡æ»¤: ä¿ç•™ {len(filtered_results)} ä¸ªç»“æœï¼Œè¿‡æ»¤ {below_threshold_count} ä¸ªä½ç›¸ä¼¼åº¦ç»“æœ")
        
        return filtered_results
    
    def _adaptive_top_k_selection(self, 
                                  results: List[RetrievalResult], 
                                  target_k: int) -> List[RetrievalResult]:
        """æ™ºèƒ½Top-Ké€‰æ‹© - åŸºäºç›¸ä¼¼åº¦æ¢¯åº¦è‡ªåŠ¨è°ƒæ•´Kå€¼"""
        if len(results) <= 1:
            return results
        
        # è®¡ç®—ç›¸ä¼¼åº¦ä¸‹é™å¹…åº¦
        similarity_drops = []
        for i in range(1, len(results)):
            drop = results[i-1].similarity_score - results[i].similarity_score
            similarity_drops.append(drop)
        
        # å¯»æ‰¾æ˜¾è‘—ä¸‹é™ç‚¹
        significant_drops = []
        for i, drop in enumerate(similarity_drops):
            if drop > self.config.relevance_drop_threshold:
                significant_drops.append(i + 1)  # +1 å› ä¸ºç´¢å¼•åç§»
        
        # å†³å®šæœ€ç»ˆçš„Kå€¼
        final_k = target_k
        
        if significant_drops:
            # å¦‚æœæœ‰æ˜¾è‘—ä¸‹é™ï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ªä¸‹é™ç‚¹
            suggested_k = significant_drops[0]
            if suggested_k < target_k:
                final_k = max(suggested_k, self.config.min_top_k)
                print(f"ğŸ¯ æ™ºèƒ½Kå€¼è°ƒæ•´: {target_k} â†’ {final_k} (æ£€æµ‹åˆ°ç›¸ä¼¼åº¦æ˜¾è‘—ä¸‹é™)")
            elif suggested_k > target_k and len(results) > target_k:
                # å¦‚æœä¸‹é™ç‚¹åœ¨target_kä¹‹åï¼Œä¿æŒåŸå§‹Kå€¼
                pass
        
        return results[:final_k]
    
    def _apply_diversity_filter(self, results: List[RetrievalResult]) -> List[RetrievalResult]:
        """åº”ç”¨ç»“æœå¤šæ ·æ€§è¿‡æ»¤ - ç§»é™¤è¿‡äºç›¸ä¼¼çš„æ–‡æ¡£"""
        if len(results) <= 1:
            return results
        
        # ç®€åŒ–ç‰ˆå¤šæ ·æ€§è¿‡æ»¤ï¼šåŸºäºæ–‡æ¡£å†…å®¹ç›¸ä¼¼åº¦
        diverse_results = [results[0]]  # æ€»æ˜¯ä¿ç•™æœ€ç›¸ä¼¼çš„ç»“æœ
        
        for result in results[1:]:
            # æ£€æŸ¥ä¸å·²é€‰ç»“æœçš„ç›¸ä¼¼åº¦
            is_diverse = True
            for selected in diverse_results:
                # ç®€å•çš„æ–‡æœ¬ç›¸ä¼¼åº¦æ£€æŸ¥ï¼ˆå¯ä»¥ç”¨æ›´é«˜çº§çš„æ–¹æ³•ï¼‰
                if self._text_similarity(result.document, selected.document) > self.config.diversity_threshold:
                    is_diverse = False
                    break
            
            if is_diverse:
                diverse_results.append(result)
        
        if len(diverse_results) < len(results):
            print(f"ğŸŒŸ å¤šæ ·æ€§è¿‡æ»¤: {len(results)} â†’ {len(diverse_results)} ä¸ªç»“æœ")
        
        return diverse_results
    
    def _text_similarity(self, text1: str, text2: str) -> float:
        """ç®€å•çš„æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆåŸºäºè¯æ±‡é‡å ï¼‰"""
        if not text1 or not text2:
            return 0.0
        
        # ç®€å•çš„Jaccardç›¸ä¼¼åº¦
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        
        intersection = words1 & words2
        union = words1 | words2
        
        return len(intersection) / len(union) if union else 0.0
    
    def _print_retrieval_stats(self, 
                              query: str, 
                              results: List[RetrievalResult], 
                              retrieval_time: float,
                              threshold: float):
        """æ‰“å°æ£€ç´¢ç»Ÿè®¡ä¿¡æ¯"""
        print(f"âœ… å‘é‡æ£€ç´¢å®Œæˆ:")
        print(f"   - æ£€ç´¢æ—¶é—´: {retrieval_time:.3f}ç§’")
        print(f"   - è¿”å›ç»“æœ: {len(results)} ä¸ª")
        
        if results:
            scores = [r.similarity_score for r in results]
            print(f"   - ç›¸ä¼¼åº¦èŒƒå›´: {min(scores):.3f} ~ {max(scores):.3f}")
            print(f"   - å¹³å‡ç›¸ä¼¼åº¦: {np.mean(scores):.3f}")
            
            above_threshold = sum(1 for r in results if r.is_above_threshold)
            print(f"   - è¶…è¿‡é˜ˆå€¼({threshold}): {above_threshold}/{len(results)} ä¸ª")
        else:
            print(f"   - âš ï¸ æ²¡æœ‰ç»“æœè¶…è¿‡ç›¸ä¼¼åº¦é˜ˆå€¼ {threshold}")
    
    def search_with_multiple_thresholds(self, 
                                       query: str,
                                       thresholds: List[float] = None,
                                       top_k: int = None) -> Dict[str, List[RetrievalResult]]:
        """ä½¿ç”¨å¤šä¸ªé˜ˆå€¼è¿›è¡Œæ£€ç´¢æ¯”è¾ƒ"""
        if thresholds is None:
            thresholds = [
                self.config.loose_threshold,
                self.config.similarity_threshold, 
                self.config.strict_threshold
            ]
        
        if top_k is None:
            top_k = self.config.default_top_k
        
        print(f"ğŸ” å¤šé˜ˆå€¼å‘é‡æ£€ç´¢: \"{query[:30]}...\"")
        print(f"   - æµ‹è¯•é˜ˆå€¼: {thresholds}")
        
        results_by_threshold = {}
        
        for threshold in thresholds:
            threshold_key = f"threshold_{threshold:.2f}"
            results = self.search(
                query=query,
                top_k=top_k,
                similarity_threshold=threshold,
                enable_adaptive_k=False  # ç¦ç”¨è‡ªé€‚åº”Kä»¥ä¾¿æ¯”è¾ƒ
            )
            results_by_threshold[threshold_key] = results
            
        # æ‰“å°æ¯”è¾ƒç»“æœ
        print(f"\nğŸ“Š å¤šé˜ˆå€¼æ£€ç´¢ç»“æœå¯¹æ¯”:")
        for threshold_key, results in results_by_threshold.items():
            threshold_val = float(threshold_key.split('_')[1])
            print(f"   - é˜ˆå€¼ {threshold_val:.2f}: {len(results)} ä¸ªç»“æœ")
        
        return results_by_threshold

    def get_retrieval_config(self) -> RetrievalConfig:
        """è·å–å½“å‰æ£€ç´¢é…ç½®"""
        return self.config
    
    def update_config(self, **kwargs):
        """æ›´æ–°æ£€ç´¢é…ç½®"""
        for key, value in kwargs.items():
            if hasattr(self.config, key):
                setattr(self.config, key, value)
                print(f"âœ… æ›´æ–°é…ç½®: {key} = {value}")
            else:
                print(f"âš ï¸ æœªçŸ¥é…ç½®é¡¹: {key}")

# å·¥å…·å‡½æ•°
def create_retrieval_config(
    similarity_threshold: float = 0.3,
    top_k: int = 5,
    enable_adaptive_k: bool = True,
    enable_diversity: bool = False) -> RetrievalConfig:
    """åˆ›å»ºæ£€ç´¢é…ç½®çš„ä¾¿æ·å‡½æ•°"""
    
    config = RetrievalConfig()
    config.similarity_threshold = similarity_threshold
    config.default_top_k = top_k
    config.enable_adaptive_k = enable_adaptive_k
    config.enable_diversity = enable_diversity
    
    return config